# Default values for astronomer.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This version number controls the default Airflow chart version that will be installed
# when creating a new deployment in the system. This is also used to ensure all
# child airflow deployments are kept up to date and on the latest version.
airflowChartVersion: 1.17.22

nodeSelector: {}
affinity: {}
tolerations: []

# Images for Astronomer
images:
  commander:
    repository: quay.io/astronomer/ap-commander
    tag: 1.1.1
    pullPolicy: IfNotPresent
  registry:
    repository: quay.io/astronomer/ap-registry
    tag: 3.0.0-5
    pullPolicy: IfNotPresent
    # httpSecret: ~
  houston:
    repository: quay.io/astronomer/ap-houston-api
    tag: 1.1.0
    pullPolicy: IfNotPresent
  astroUI:
    repository: quay.io/astronomer/ap-astro-ui
    tag: 1.0.33
    pullPolicy: IfNotPresent
  dbBootstrapper:
    repository: quay.io/astronomer/ap-db-bootstrapper
    tag: 1.0.6
    pullPolicy: IfNotPresent
  vector:
    repository: quay.io/astronomer/ap-vector
    tag: "0.51.0"
    pullPolicy: IfNotPresent


securityContext:
  runAsNonRoot: true

astroUI:
  replicas: 2
  env: []
  # This only applies when replicas > 3
  maxUnavailable: 25%
  resources: {}
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi
  readinessProbe: {}
  livenessProbe: {}
  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
  podAnnotations: {}

houston:
  prismaConnectionLimit: 5
  replicas: 2
  # This only applies when replicas > 3
  maxUnavailable: 25%
  livenessProbe: {}
    # httpGet:
    #   path: /v1/healthz
    #   port: {{ .Values.ports.houstonHTTP }}
    # initialDelaySeconds: 30
    # periodSeconds: 10
    # failureThreshold: 10
  readinessProbe: {}
    # httpGet:
    #   path: /v1/healthz
    #   port: {{ .Values.ports.houstonHTTP }}
    # initialDelaySeconds: 30
    # periodSeconds: 10
    # failureThreshold: 10

  # Houston can regenerate its certificate authority on each 'helm upgrade'
  # or leave it alone. If this is set to 'true', then all users are logged
  # out on each helm upgrade. This is usually preferred 'true' for the case of
  # enterprise, and 'false' for the case of SaaS, where upgrades should be
  # without user interruption.
  regenerateCaEachUpgrade: false
  # Houston datastore
  backendSecretName: ~
  backendConnection:
    {}
    # user: ~
    # pass: ~
    # host: ~
    # port: ~
    # db: ~

  # Airflow backends
  airflowBackendSecretName: ~
  airflowBackendConnection:
    {}
    # user: ~
    # pass: ~
    # host: ~
    # port: ~
    # db: ~

  # This specifies an optional secret name to use to sign JWTs.
  # If not specified, we use an auto-generated, self-signed certificate.
  jwtSigningKeySecretName: ~
  jwtSigningCertificateSecretName: ~

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  env: []

  # For example
  #   `kubectl create secret generic my-secret --from-literal=connection=smtps://USERNAME:PW@HOST/?pool=true`
  # and then set:
  #
  # secret:
  # - envName: "EMAIL__SMTP_URL"
  #   secretName: "my-scret"
  #   secretKey: "connection"
  secret: []

  resources: {}
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Any Houston configuration. Reference here:
  # https://github.com/astronomer/houston-api/blob/main/config/default.yaml
  config:
    nats:
      ackWait: 600000

  hostAliases: []

  # Worker to connect to NATS
  worker:
    enabled: true
    replicas: 2
    readinessProbe: {}
    livenessProbe: {}
    hostAliases: []

  # Vector sidecar for audit log shipping to AWS CloudWatch or GCP Cloud Logging.
  # When enabled, a Vector sidecar container is added to both Houston API
  # and Houston Worker pods, along with a log wrapper script that redirects
  # stdout/stderr to files which Vector reads and ships to the configured sink.
  loggingSidecar:
    enabled: false

    resources:
      requests:
        memory: "128Mi"
        cpu: "50m"
      limits:
        memory: "256Mi"
        cpu: "200m"

    # AWS CloudWatch Logs configuration
    cloudwatch:
      enabled: false
      region: ""
      logGroupName: "/astronomer/houston/audit"
      # Use IRSA (IAM Roles for Service Accounts) for authentication.
      # When true, no access keys are needed; the service account must be
      # annotated with eks.amazonaws.com/role-arn via houston.serviceAccount.annotations.
      useIRSA: true
      # Secret containing aws_access_key_id and aws_secret_access_key keys.
      # Only used when useIRSA is false.
      secretName: "houston-cloudwatch-creds"

    # GCP Cloud Logging (formerly Stackdriver) configuration
    gcpCloudLogging:
      enabled: false
      # GCP project ID to which logs are published (required).
      projectId: ""
      # Custom log ID that identifies this log stream in Cloud Logging.
      logId: "houston-audit"
      # Monitored resource type. "k8s_container" is the standard for GKE pods.
      resource:
        type: "k8s_container"
      # Map the "level" field in log entries to GCP severity levels.
      severityKey: "level"
      # Use GKE Workload Identity for authentication (recommended).
      # When true, no credentials file is needed; the K8s service account must
      # be annotated with iam.gke.io/gcp-service-account via
      # houston.serviceAccount.annotations.
      useWorkloadIdentity: true
      # Name of the K8s Secret containing a GCP service account JSON key file.
      # Only used when useWorkloadIdentity is false.
      credentialsSecretName: "houston-gcp-logging-creds"
      # Key within the secret that holds the JSON key file.
      credentialsSecretKey: "key.json"

    # Elasticsearch configuration
    elasticsearch:
      enabled: false
      # Endpoint URL for the Elasticsearch cluster.
      # When empty, Houston defaults to external-es-proxy if global.customLogging.enabled,
      # otherwise it uses the in-cluster Elasticsearch service.
      endpoint: ""                              # e.g. "https://es.example.com:9200"
      # Index name pattern. Supports strftime format for date-based indices.
      index: "houston-audit-%Y.%m.%d"
      # Elasticsearch API version.
      apiVersion: "v8"
      # Auth strategy: "basic" or "none".
      # When "basic", a K8s Secret with "username" and "password" keys is required.
      auth:
        strategy: "basic"
        secretName: "houston-elasticsearch-creds"
      # TLS: enable if using an https endpoint with a custom/self-signed CA.
      # When enabled, the named secret (containing a PEM CA cert) is mounted.
      tls:
        enabled: false
        caSecretName: ""

  # Automatically upgrade Airflow deployments to the latest
  # version specified by Houston configuration.
  # This runs as a Job after helm upgrades.
  upgradeDeployments:
    # Enable this helm hook on upgrade
    enabled: true

    # Only run on deployments marked as canary
    canary: false

  # Cleanup deployments that have been soft-deleted in Houston
  # This runs as a CronJob
  cleanupDeployments:
    # Enable cleanup CronJob
    enabled: true

    # Default here is to run at midnight every night https://crontab.guru/#0_0_*_*_*
    schedule: "0 0 * * *"

    # Cleanup deployments older than this many days
    olderThan: 14

    # Print out the deployments that should be cleaned up and skip actual cleanup
    dryRun: false

    # Only run on deployments marked as canary
    canary: false

    readinessProbe: {}
    livenessProbe: {}

  # Cleanup airflow db data
  # This runs as a CronJob
  cleanupAirflowDb:
    # Enable cleanup CronJob
    enabled: false

    # Default run is at 5:23 every morning https://crontab.guru/#23_5_*_*_*
    schedule: "23 5 * * *"

    # Cleanup deployments older than this many days
    olderThan: 365

    # Output path of archived data csv export
    outputPath: "/tmp"

    # Delete archived tables
    dropArchives: true

    # Print out the deployments that should be cleaned up and skip actual cleanup
    dryRun: false

    # Name of file storage provider, supported providers - aws/azure/gcp/local
    provider: local

    # Name of the provider bucket name / local file path
    bucketName: "/tmp"

    # Airflow provider connection id to connect to provider bucket, read more - https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html
    providerEnvSecretName: ""

    # Run cleanup on specific table or list of tables in a comma separated format
    tables: ""

    readinessProbe: {}
    livenessProbe: {}

  # Cleanup task usage data and task audit data in Houston
  # This runs as a CronJob
  cleanupTaskUsageData:
    # Run at 23:40 every night
    schedule: "40 23 * * *"  # https://crontab.guru/#40_23_*_*_*

    # Cleanup deployments older than this many days
    olderThan: 90

    # Print out the deployments that should be cleaned up and skip actual cleanup
    dryRun: false

    # Only run on deployments marked as canary
    canary: false

    readinessProbe: {}
    livenessProbe: {}

  # Cleanup task usage data and task audit data in Houston
  # This runs as a CronJob
  cleanupDeployRevisions:
    # Enable cleanup CronJob
    enabled: true

    # Run at 23:11 every night
    schedule: "11 23 * * *"  # https://crontab.guru/#11_23_*_*_*

    # Cleanup deploy revisions older than this many days
    olderThan: 90

    readinessProbe: {}
    livenessProbe: {}

  # Cleanup cluster audits in Houston
  # This runs as a CronJob
  cleanupClusterAudits:
    # Enable cleanup CronJob
    enabled: true

    # Run at 23:49 every night
    schedule: "49 23 * * *"  # https://crontab.guru/#49_23_*_*_*

    # Cleanup deploy revisions older than this many days
    olderThan: 90
    readinessProbe: {}
    livenessProbe: {}

  # Check for Astronomer Platform Updates
  # This runs as a CronJob
  updateCheck:
    # Enable check updates CronJob
    enabled: false

    # url for update service
    url: https://updates.astronomer.io/astronomer-platform

    # Default here is to run at midnight every night https://crontab.guru/#0_0_*_*_*
    schedule: "0 0 * * *"

    readinessProbe: {}
    livenessProbe: {}

  # Check for Astronomer Runtime Updates
  # This runs as a CronJob
  updateRuntimeCheck:
    # Enable check updates CronJob
    enabled: true

    # url for update service
    url: https://updates.astronomer.io/astronomer-runtime

    # Default here is to run at 00:43 every night https://crontab.guru/#43_0_*_*_*
    schedule: "43 0 * * *"

    readinessProbe: {}
    livenessProbe: {}

  # Populate daily task usage data
  # This runs as a CronJob

  populateDailyTaskMetrics:
    # Default here is to run at 00:08 every night
    schedule: "8 0 * * *"

    # Print out the aggregated daily task usage data that should be inserted and skip actual insertion
    dryRun: false

    readinessProbe: {}
    livenessProbe: {}

  populateHourlyTaskAuditMetrics:
    # Run at minute 57 every hour https://crontab.guru/#57_*_*_*_*
    schedule: "57 * * * *"

    readinessProbe: {}
    livenessProbe: {}

  # Sync dataplane clusters in Houston
  # This runs as a CronJob
  syncDataplaneClusters:
    # Enable sync dataplane clusters CronJob
    enabled: true

    # Default here is to run at the top of every hour https://crontab.guru/#0_*_*_*_*
    schedule: "0 * * * *"

    readinessProbe: {}
    livenessProbe: {}

  runtimeReleasesConfigMapName: ~
  runtimeReleasesConfig:
    # example of usage:
    # below are default mandatory fields
    # runtimeVersions:
    #  12.1.1:
    #    metadata:
    #      airflowVersion: 2.10.2
    #      channel: stable

  # Add extra containers here
  extraContainers: []

  # Add volumes to your containers
  extraVolumes: []

  # Add custom annotation for houston ingress
  ingress:
    annotation: {}

  updateResourceStrategy:
    readinessProbe: {}
    livenessProbe: {}

  dbMigration:
    readinessProbe: {}
    livenessProbe: {}

  bootstrapper:
    readinessProbe: {}
    livenessProbe: {}

  waitForDB:
    readinessProbe: {}
    livenessProbe: {}

  taskUsageMetrics:
    readinessProbe: {}
    livenessProbe: {}

configSyncer:
  enabled: true
  # If not provided, will generate a random hour and minutes to spread cronjob workloads.
  schedule: ~
  securityContext: {}
  resources: {}
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
  readinessProbe: {}
  livenessProbe: {}


commander:
  replicas: 2
  env: []
  # This only applies when replicas > 3
  maxUnavailable: 25%
  resources:
    {}
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi
  livenessProbe: {}
    # failureThreshold: 5
    # httpGet:
    #   path: /healthz
    #   port: {{ .Values.ports.commanderHTTP }}
    #   scheme: HTTP
    # initialDelaySeconds: 10
    # periodSeconds: 10
  readinessProbe: {}
    # httpGet:
    #   path: /healthz
    #   port: {{ .Values.ports.commanderHTTP }}
    # initialDelaySeconds: 10
    # periodSeconds: 10
  podAnnotations: {}

  # Add custom annotation for commander ingress
  ingress:
    annotation: {}
      #nginx.ingress.kubernetes.io/rate-limit: "100"

  airGapped:
    # Enable airgapped mode
    enabled: false
  upgradeTimeout: 600

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  hostAliases: []

  # Add extra containers to your commander deployment.
  extraContainers: []

  # Add extra volumes to your commander deployment.
  extraVolumes: []

  # Values for Dataplane Metadata
  cloudProvider: ""
  commanderUrl: ""
  region: ""
  jwksHook:
    retryAttempts: 2
    retryDelay: 10
    extraEnv: []

registry:
  # flag to bypass secure (tls) authentication to astronomer registry
  enableInsecureAuth: False
  replicas: 1
  resources: {}
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

  livenessProbe: {}
    # httpGet:
    #   path: /
    #   port: {{ .Values.ports.registryHTTP }}
    # initialDelaySeconds: 10
    # periodSeconds: 10
    # timeoutSeconds: 5

  readinessProbe: {}
    # httpGet:
    #   path: /
    #   port: {{ .Values.ports.registryHTTP }}
    # initialDelaySeconds: 10
    # periodSeconds: 10
    # timeoutSeconds: 5

  podSecurityContext:
    fsGroup: 1000
    runAsGroup: 1000
    runAsUser: 1000
  extraEnv: []

  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
    # Specifies whether a scc privilege should be created for custom sa
    sccEnabled: false

  persistence:
    # Enable persistent storage
    enabled: true
    # Size of volume to provision
    size: 100Gi
    # If using a custom storageClass, pass name ref to all statefulSets here
    storageClassName: ~
    annotations: {}

  auth:
    secretName: ~
    connection: ~
    service: "docker-registry"
    issuer: "houston"

  gcs:
    enabled: false
    bucket: ~
    useKeyfile: true
    keyfile: /var/gcs-keyfile/astronomer-gcs-keyfile
    rootdirectory: /
    chunksize: "5242880"

  azure:
    enabled: false
    accountname: ~
    accountkey: ~
    container: ~
    realm: ~

  s3:
    enabled: false
    accesskey: ~
    secretkey: ~
    region: ~
    bucket: ~
    encrypt: false
    keyid: ~
    rootdirectory: ~
    regionendpoint: ~

  notifications:
    timeout: 30s

  redirect:
    disable: false

  logLevel: info

  podAnnotations: {}

  hostAliases: []

ports:
  houstonHTTP: 8871
  commanderHTTP: 8880
  commanderGRPC: 50051
  astroUIHTTP: 8080
  registryHTTP: 5000
  registryScrape: 5001
  commanderSidecarHTTP: 8080
  commanderSidecarGRPC: 9090
