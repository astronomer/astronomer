#######################
## Fluentd ConfigMap ##
#######################
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "fluentd.fullname" . }}
  labels:
    tier: logging
    component: {{ template "fluentd.name" . }}
    chart: {{ template "fluentd.chart" . }}
    heritage: {{ .Release.Service }}
    release: {{ .Release.Name }}
data:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  containers.input.conf: |-
    # Grab logs from hosts
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file "/var/log/#{ENV['RELEASE']}-fluentd-containers.log.pos"
      exclude_path ["/var/log/*fluentd*", "/var/log/containers/*fluentd*"]
      <parse>
        @type multi_format
        <pattern>
          format json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
         # Example log we are parsing
         # 2020-11-11T19:22:45.526814634+00:00 stdout F 10.130.4.1 - - [11/Nov/2020:19:22:45 +0000] "GET /meteoroidal-kiloparsec-2912/airflow/health HTTP/1.1" 200 187 "-" "kube-probe/1.17+"
         <pattern>
           format /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
           # https://docs.ruby-lang.org/en/2.4.0/Time.html#method-c-strptime
           time_format %Y-%m-%dT%H:%M:%S.%N%z
         </pattern>
      </parse>
      tag raw.kubernetes.*
      read_from_head true
    </source>
    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>
  forward.input.conf: |-
    # Takes the messages sent over TCP
    <source>
      @type forward
    </source>
  monitoring.conf: |-
    # Prometheus Exporter Plugin
    # input plugin that exports metrics
    <source>
      @type prometheus
    </source>
    <source>
      @type monitor_agent
    </source>
    # input plugin that collects metrics from MonitorAgent
    <source>
      @type prometheus_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
    # input plugin that collects metrics for output plugin
    <source>
      @type prometheus_output_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
    # input plugin that collects metrics for in_tail plugin
    <source>
      @type prometheus_tail_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
  output.conf: |
    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>

    # Filter down by namespace and component (scheduler/webserver/worker/triggerer/git-sync-relay/dag-server/airflow-downgrade)
    <filter kubernetes.**>
      @type grep
      <regexp>
        {{- if and .Values.global.features.namespacePools.enabled (gt (len .Values.global.features.namespacePools.namespaces.names) 0) }}
        key $.kubernetes.namespace_name
        pattern ^({{ join "|" .Values.global.features.namespacePools.namespaces.names }})$
        {{- else if or .Values.global.manualNamespaceNamesEnabled .Values.global.disableManageClusterScopedResources }}
        key $.kubernetes.namespace_name
        # fluentd should gather logs from all namespaces if manualNamespaceNamesEnabled is enabled
        pattern "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$"
        {{ else }}
        # only retrieve logs from namespaces containing the label "platform", which is added to all namespaces used to host Airflow Deployments.
        # this makes sure that if customers enable namespaces pools, then disable it, we can still get the logs from these deployments.
        key $.kubernetes.namespace_labels.platform
        pattern "{{ .Release.Name }}"
        {{ end }}
      </regexp>
      <regexp>
        key $.kubernetes.labels.component
        pattern ^(scheduler|webserver|worker|triggerer|git-sync-relay|dag-server|airflow-downgrade)$
      </regexp>
    </filter>

    # Drop unncessesary fields and rename some fields
    <filter kubernetes.**>
      @type record_transformer
      enable_ruby
      renew_record
      <record>
        component ${record["kubernetes"]["labels"]["component"]}
        workspace ${record["kubernetes"]["labels"]["workspace"]}
        release ${record["kubernetes"]["labels"]["release"]}
        message ${record["log"]}
        date_nano ${time.strftime('%Y-%m-%dT%H:%M:%S.%NZ')}
      </record>
    </filter>

    # Attempt to parse any message fields that contain JSON
    <filter kubernetes.**>
      @type parser
      format json
      key_name message
      replace_invalid_sequence true
      emit_invalid_record_to_error false
      reserve_data true
    </filter>

    # <match kubernetes.**>
    #   @type rewrite_tag_filter
    #   <rule>
    #     key component
    #     pattern ^(scheduler)$
    #     tag airflow.system
    #   </rule>
    #   <rule>
    #     key component
    #     pattern ^(webserver)$
    #     tag airflow.system
    #   </rule>
    #   <rule>
    #     key component
    #     pattern ^(worker)$
    #     tag airflow.task
    #   </rule>
    # </match>

    # If we have a dag_id, assume its a task log
    <match kubernetes.**>
      @type rewrite_tag_filter
      <rule>
        key dag_id
        pattern .+
        tag airflow.task
      </rule>
      <rule>
        key component
        pattern .+
        tag airflow.system
      </rule>
    </match>

    # Also add log_id to airflow.task logs
    <filter airflow.task.**>
      @type record_transformer
      enable_ruby
      <record>
        log_id ${ record.has_key?("log_id") ? record["log_id"] : record["dag_id"] + "_" + record["task_id"] + "_" + record["execution_date"] + "_" + record["try_number"] }
        offset ${time = Time.now; time.to_i * (10 ** 9) + time.nsec}
      </record>
    </filter>

    # Send off to elasticsearch
    <match airflow.**>
      @type copy
      <store>
        @id elasticsearch
        @type elasticsearch_dynamic
        @log_level info
        include_timestamp true
        reconnect_on_error true
        reload_on_failure true
        reload_connections false
        request_timeout 120s
        suppress_type_name true
        host "#{ENV['OUTPUT_HOST']}"
        port "#{ENV['OUTPUT_PORT']}"
        index_name {{ include "fluentd.indexNamePrefix" .}}.${record["release"]}.${Time.at(time).getutc.strftime(@logstash_dateformat)}
        templates { "fluentdindextemplate": "/host/index_template.json"}
        template_overwrite true
        <buffer>
          @type file
          path "/var/log/fluentd-buffers/#{ENV['RELEASE']}-kubernetes.system.buffer"
          flush_mode interval
          flush_at_shutdown true
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
          queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
          overflow_action block
        </buffer>
      </store>
      {{- if .Values.s3.enabled }}
      <store>
        @type s3
        @id s3
        @log_level info
        {{- include "fluentd.s3Config" . | indent 8 }}
        <buffer>
          @type file
          path "/var/log/fluentd-buffers/#{ENV['RELEASE']}-s3-kubernetes.system.buffer"
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
          queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
          overflow_action drop_oldest_chunk
        </buffer>
      </store>
      {{- end }}
      {{- if .Values.extraLogStores }}
{{ .Values.extraLogStores | indent 6}}
      {{- end }}
    </match>
