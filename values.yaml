#################################
## Astronomer global configuration
#################################
global:
  # Base domain for all subdomains exposed through ingress
  baseDomain: ~

  # Name of secret containing TLS certificate
  tlsSecret: astronomer-tls

  # List of secrets containing private CA certificates
  privateCaCerts: []
  # Most users with private CA will already have their node
  # images created including the cert to trust in the appropriate
  # location. If not, it is necessary to configure Docker (or containerd)
  # on all nodes to trust the private root CA. This will allow
  # kubelet to pull from the Astronomer registry that has been signed
  # by the same private CA.
  privateCaCertsAddToHost:
    enabled: false
    hostDirectory: /etc/docker/certs.d

  # Use kube-lego
  acme: false

  # If RBAC on cluster is enabled
  rbacEnabled: true

  # URL to the Astronomer helm repo
  helmRepo: "https://helm.astronomer.io"

  # Host and port of where tiller is running in Kubernetes
  helmHost: "tiller-deploy.kube-system.svc.cluster.local:44134"

  # Single namespace mode
  singleNamespace: false

  # Enables necessary components for compatibility with Istio Service Mesh
  istio:
    enabled: false
    rootNamespace: "istio-config"

  # Enables necessary components for Velero (Velero, Grafana Dashboard, Prometheus Alerts)
  veleroEnabled: false

  # Enable default postgresql database.
  # This is not recommended for production.
  postgresqlEnabled: false

  # Enables a node exporter DaemonSet for node-level metrics
  nodeExporterEnabled: true

  prometheusPostgresExporterEnabled: false

  # Enables blackbox exporter
  blackboxExporterEnabled: false

  # Used to enable Celery autoscaling
  kedaEnabled: false

  # Used to enable nats-server
  nats:
    enabled: true
    replicas: 3

  # Used to enable nats-streaming
  stan:
    enabled: true
    replicas: 3

  # If PodSecurityPolicies (PSP) should be enabled
  pspEnabled: false

  # Do you want to apply the global, default deny ingress network policy?
  defaultDenyNetworkPolicy: true

  # Enable security context constraints required for OpenShift
  sccEnabled: false

  # Enable values required for use with Microsoft Azure
  azure:
    enabled: false

  # Set nodeSelector, affinity, and tolerations values for platform and deployment related pods.
  # This allows for separation of platform and airflow pods between kubernetes node pools.
  # Pods in the platformNodePool include alertmanager, cli-install, commander, houston, kube-replicator, astro-ui, prisma,
  # registry, es-client, es-data, es-exporter, es-master, nginx-es, grafana, kibana, kube-state, nginx, nginx-default, prometheus.
  # nodeSelector, affinity, and tolerations values for airflow deployment pods are assigned via houston config.
  # See more information on pod / node assignment here: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  platformNodePool:
    nodeSelector: &platformNodeSelector
      {}
    affinity: &platformAffinity
      {}
    tolerations: &platformTolerations
      []

  privateRegistry:
    enabled: false
    repository: ~

  # SSL support for using SSL connections to encrypt client/server communication between database and Astronomer platform
  ssl:
    enabled: false
    mode: "prefer"
    # we need seperate mode for grafana:
    # grafana starting from (7.5.0) only supports sslmodes: disable/require/verify-ca/verify-full
    # https://github.com/grafana/grafana/blob/master/CHANGELOG.md#750-beta1-2021-03-04 (Postgres: SSL certification)
    grafana:
      sslmode: "require"

  # Storage class for persistent volumes. If you have multiple storage classes available this will force all charts with persistent
  # volumes to use the one specified here.
  # storageClass: ~

  openShift:
    # If running on an OpenShift cluster, use the existing Router for public traffic ingress. This sets up
    # routes to form the Router to our Nginx (which enforces wuth), and then from there to the actual sercie
    useRouter: false

#################################
## Default tagged groups enabled
#################################
tags:
  # Enable platform components by default (nginx, astronomer)
  platform: true

  # Enable monitoring stack (prometheus, kube-state, grafana)
  monitoring: true

  # Enable logging stack (elasticsearch, fluentd, kibana)
  logging: true

  # Kubed
  kubed: true

  # NATS Streaming
  stan: true

#################################
## Astronomer configuration
#################################
astronomer:
  astroUI:
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "1024Mi"

  houston:
    resources:
      requests:
        cpu: "500m"
        memory: "1024Mi"
      limits:
        cpu: "1000m"
        memory: "2048Mi"

  commander:
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "500m"
        memory: "1024Mi"

  registry:
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "500m"
        memory: "1024Mi"

    persistence:
      enabled: true
      size: "100Gi"

  install:
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "1024Mi"

#################################
## Nginx configuration
#################################
nginx:
  # Configure resources
  resources:
    requests:
      cpu: "500m"
      memory: "1024Mi"
    limits:
      cpu: "1"
      memory: "2048Mi"

  # String IP address the nginx ingress should bind to
  loadBalancerIP: ~

  # List used to restrict IPs that can reach the nginx ingress
  loadBalancerSourceRanges: []

  # Dict of arbitrary annotations to add to the nginx ingress
  ingressAnnotations: {}

#################################
## Grafana configuration
#################################
grafana:
  # Configure resources
  resources:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "500m"
      memory: "1024Mi"

  dashboards:
    {}
    # default:
    #   velero:
    #     file: dashboards/velero.json

#################################
## Prometheus configuration
#################################
prometheus:
  podLabels: {}
  # Data retention
  retention: 15d

  # Persistence configuration
  persistence:
    enabled: true
    size: "150Gi"

  # Configure resources
  resources:
    requests:
      cpu: "1000m"
      memory: "4Gi"
    limits:
      cpu: "2000m"
      memory: "8Gi"

#################################
## KEDA configuration
#################################

keda:
  keda:
    nodeSelector:
      <<: *platformNodeSelector
    affinity:
      <<: *platformAffinity
    tolerations: *platformTolerations

nats:
  nodeSelector:
    <<: *platformNodeSelector
    affinity:
      <<: *platformAffinity
    tolerations: *platformTolerations
  resources:
    requests:
      cpu: "75m"
      memory: "30Mi"
    limits:
      cpu: "250m"
      memory: "100Mi"

stan:
  nodeSelector:
    <<: *platformNodeSelector
    affinity:
      <<: *platformAffinity
    tolerations: *platformTolerations
  resources:
    requests:
      cpu: "75m"
      memory: "30Mi"
    limits:
      cpu: "250m"
      memory: "100Mi"

#################################
## Blackbox Exporter configuration
#################################
prometheus-blackbox-exporter:
  # Configure resources
  resources:
    requests:
      cpu: "50m"
      memory: "70Mi"
    limits:
      cpu: "100m"
      memory: "200Mi"

  # define what astronomer platform services will be checked
  # for up/down status. Enable this will also include
  # the required network policies
  astroServices:
    commander:
      enabled: true
    houston:
      enabled: true
    registry:
      enabled: true
    grafana:
      enabled: true
    elasticsearch:
      enabled: true
    kibana:
      enabled: true
    cliInstall:
      enabled: true

#################################
## Elasticsearch configuration
#################################
elasticsearch:
  # Common configuration
  common:
    persistence:
      enabled: true

  # Configure client nodes
  client:
    # Match resources.requests.memory
    heapMemory: "2g"

    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "2"
        memory: "4Gi"

  # Configure data nodes
  data:
    # Match resources.requests.memory
    heapMemory: "2g"

    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "2"
        memory: "4Gi"

    persistence:
      size: "100Gi"

  # Configure master nodes
  master:
    # Match resources.requests.memory
    heapMemory: "2g"

    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "2"
        memory: "4Gi"

    persistence:
      size: "20Gi"

#################################
## Kibana configuration
#################################
kibana:
  # Configure resources
  resources:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "500m"
      memory: "1024Mi"

#################################
## Fluentd configuration
#################################
# fluentd:
#   # Configure resources
#   resources:
#     requests:
#       cpu: "250m"
#       memory: "512Mi"
#     limits:
#       cpu: "500m"
#       memory: "1024Mi"

#################################
## Kube State configuration
#################################
kubeState:
  # Configure resources
  resources:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "500m"
      memory: "1024Mi"

#################################
## KubeD configuration
#################################
kubed:
  # Configure resources
  resources:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "2"
      memory: "1024Mi"
